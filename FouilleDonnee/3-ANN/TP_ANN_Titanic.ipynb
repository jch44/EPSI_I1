{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TP : Classification Binaire avec PyTorch – Titanic\n",
        "\n",
        "## **Objectif du TP**\n",
        "Prédire si un passager du Titanic a **survécu ou non** à partir de ses caractéristiques (âge, sexe, classe, etc.) en utilisant un **réseau de neurones fully-connected** avec **PyTorch**.\n",
        "\n",
        "---\n",
        "\n",
        "## **Compétences abordées**\n",
        "\n",
        "| Thème | Détail |\n",
        "|------|--------|\n",
        "| **Préparation des données** | Chargement, nettoyage, split train/dev |\n",
        "| **PyTorch Dataset & DataLoader** | Gestion efficace des batchs |\n",
        "| **Modèle personnalisé** | `nn.Module`, couches cachées, dropout, ReLU |\n",
        "| **Boucle d'entraînement** | `optimizer.zero_grad()`, `loss.backward()` |\n",
        "| **Évaluation** | Accuracy, CrossEntropyLoss |\n",
        "| **Soumission Kaggle** | Format CSV |\n",
        "| **(Bonus)** | Grid Search + Validation Croisée |\n",
        "\n",
        "---\n",
        "\n",
        "## **Consignes**\n",
        "- Complétez **chaque cellule de code** en suivant les instructions en **Markdown**.\n",
        "- Les **imports sont fournis**.\n",
        "- Testez à chaque étape !\n",
        "- **Bonus optionnel** en fin de TP.\n",
        "- Vous pouvez interroger un LLM pour déboguer votre modèle, mais vous devez expliquer les modifications proposées et pourquoi vous les acceptez ou non.\n",
        "---\n",
        "\n",
        "**Bon courage !**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **0. Imports (déjà fournis)**\n",
        "\n",
        "Exécutez cette cellule **sans modification**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# Device (GPU si disponible)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device utilisé : {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **1. Hyperparamètres**\n",
        "\n",
        "Définissez les hyperparamètres du modèle. Vous les modifierez plus tard pour améliorer les performances.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MODIFIEZ CES VALEURS POUR AMÉLIORER LE MODÈLE !\n",
        "HIDDEN_SIZE = ...      # Ex: 50\n",
        "NUM_LAYERS = ...       # Ex: 3 (nombre de couches cachées)\n",
        "DROPOUT_PROB = ...     # Ex: 0.2\n",
        "LEARNING_RATE = ...    # Ex: 0.01\n",
        "NUM_EPOCHS = ...       # Ex: 50\n",
        "BATCH_SIZE = ...       # Ex: 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **2. Chargement et préparation des données**\n",
        "\n",
        "- Chargez `train_clean.csv` et `test_clean.csv`\n",
        "- Extrayez :\n",
        "  - `X` : toutes les colonnes **à partir de la 3e** (index 2)\n",
        "  - `y` : la colonne **Survived** (index 1)\n",
        "- Convertissez en `np.float32` pour `X` et `np.int64` pour `y`\n",
        "- Séparez en `train` (90%) et `dev` (10%) avec `stratify=y` et `random_state=42`\n",
        "\n",
        "**À compléter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **3. Dataset PyTorch**\n",
        "\n",
        "Créez une classe `TitanicDataset` qui hérite de `torch.utils.data.Dataset`.\n",
        "\n",
        "Elle doit :\n",
        "- Accepter `X` et `y` (optionnel)\n",
        "- Convertir les données en tenseurs PyTorch\n",
        "- Implémenter `__len__` et `__getitem__`\n",
        "\n",
        "**À compléter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **4. DataLoaders**\n",
        "\n",
        "Créez trois `DataLoader` :\n",
        "- `train_loader` → `shuffle=True`\n",
        "- `dev_loader` → `shuffle=False`\n",
        "- `test_loader` → données de test (sans `y`)\n",
        "\n",
        "**À compléter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **5. Modèle : Réseau de neurones**\n",
        "\n",
        "Créez une classe `TitanicModel` avec :\n",
        "- `num_layers` couches cachées de taille `hidden_size`\n",
        "- Activation **ReLU**\n",
        "- **Dropout** après chaque couche cachée\n",
        "- Sortie : 2 classes (utilisez `nn.Linear` final)\n",
        "- Utilisez `nn.Sequential` pour construire le réseau\n",
        "\n",
        "**À compléter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **6. Fonction de coût et optimiseur**\n",
        "\n",
        "- `criterion` : `CrossEntropyLoss`\n",
        "- `optimizer` : `Adam` avec le `learning_rate` défini\n",
        "\n",
        "**À compléter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **7. Boucle d'entraînement (1 époque)**\n",
        "\n",
        "Écrivez une fonction `train_epoch` qui :\n",
        "- Met le modèle en mode `.train()`\n",
        "- Parcourt les batchs\n",
        "- Calcule la perte, fait `backward()` et `step()`\n",
        "- Retourne la **perte moyenne**\n",
        "\n",
        "**À compléter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **8. Évaluation**\n",
        "\n",
        "Écrivez une fonction `evaluate` qui :\n",
        "- Met le modèle en `.eval()`\n",
        "- Désactive le gradient (`torch.no_grad()`)\n",
        "- Calcule l'**accuracy** sur le dataset de validation\n",
        "\n",
        "**À compléter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **9. Entraînement complet**\n",
        "\n",
        "Boucle sur `NUM_EPOCHS` :\n",
        "- Appel à `train_epoch`\n",
        "- Toutes les 10 époques : afficher l'accuracy sur `dev`\n",
        "\n",
        "**À compléter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **10. Prédiction sur le test & Soumission Kaggle**\n",
        "\n",
        "- Passez le modèle en `.eval()`\n",
        "- Parcourez `test_loader`\n",
        "- Récupérez les prédictions avec `torch.max(..., 1)`\n",
        "- Générez `submission.csv` avec `PassengerId` et `Survived`\n",
        "\n",
        "**À compléter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **EXERCICE BONUS (OPTIONNEL)**\n",
        "\n",
        "### **Grid Search + Validation Croisée**\n",
        "\n",
        "> **Objectif** : Trouver automatiquement les meilleurs hyperparamètres.\n",
        "\n",
        "**À faire (seulement si vous avez fini !)**\n",
        "\n",
        "1. Utilisez `KFold` pour diviser les données\n",
        "2. Testez plusieurs valeurs de :\n",
        "   - `learning_rate`\n",
        "   - `dropout_prob`\n",
        "   - `hidden_size`\n",
        "3. Entraînez un modèle pour chaque combinaison\n",
        "4. Gardez le modèle avec la **meilleure accuracy moyenne**\n",
        "\n",
        "**Indice** : Utilisez `ParameterGrid` de `sklearn`\n",
        "\n",
        "---\n",
        "\n",
        "**Question** : Pourquoi le Grid Search est-il utile ? Donnez un exemple de compromis entre `dropout` élevé et sous-apprentissage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Votre code Grid Search ici (optionnel)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
